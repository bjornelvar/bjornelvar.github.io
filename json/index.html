[ 
  
  
    
      
      {
      "title": "Canvas Crisis",
      "url": "https://bjornelvar.dev/projects/canvas-crisis/",
      "body": "\nPLAY HERE\nDescription\nCanvas Crisis is a 2D game created in Unity. It is a platformer where you can paint the world to your liking to solve the levels. You can paint the platforms and the tiles around you to make the player jump higher, climb up walls or just go faster. The game was designed and programmed in 2 weeks.\nThis game was part of the 3-week course Computer Game Design and Development at Reykjavik University. The course was taught by Steingerður Lóa and our group was invited to present our game and to represent Reykjavik University at the UT Messan event in Reykjavik.\n"
      }
    ,
    
    
      
      {
      "title": "Anti-Clockwise Rocket Science",
      "url": "https://bjornelvar.dev/projects/anti-clockwise-rocket-science/",
      "body": "\nPLAY HERE\nDescription\nAnti-Clockwise Rocket Science is what is best described as a 1 player ping pong game. The objective is to keep hitting the ball, bouncing it back and forth between yourself or your friendly UFO. This game was created in the first week of the 3-week course Computer Game Design and Development at Reykjavik University.\nI wanted to make this game as zen as possible and I believe I achieved that. I wanted the game to never increase in difficulty, but rather to be a relaxing experience completed by the background music and sound effects.\n"
      }
    ,
    
    
      
      {
      "title": "Chicago Data Analysis",
      "url": "https://bjornelvar.dev/projects/chicago-data-analysis/",
      "body": "\nJUPYTER NOTEBOOK\nDescription\nFor my final project in Data Analysis, I decided to analyze the Chicago Crime datasets from the Chicago Data Portal. The datasets used were Crimes 2020, Crimes 2021, Crimes 2022. The dataset could be expanded to include more yearly datasets but for the scope of the project, it was important to keep it minimal and manageable, but still useful and of some significance. From there I did some merging with other datasets and then some preprocessing to get the data into a format that I could work with.\nWhat I set out to do was to explore the existence of racial bias in Chicago's Police Department. I also set out to train a model to predict if a crime would involve a firearm or not.\nLink to the Jupyter Notebook\n"
      }
    ,
    
    
      
      {
      "title": "NBA Scores: An Alfred Workflow",
      "url": "https://bjornelvar.dev/projects/nba-scores-alfred/",
      "body": "\n\n*Featured on Alfred Gallery!*\nDescription\nOne evening, my partner asked me what games were on tonight and I instinctively went to type nba in Alfred. I of course didn't have any workflow for it, so I decided to build one myself. I used the NBA API to get the data and then built a workflow around it using Python. And a lot of JSON parsing.\nIf you're interested in that kind of stuff, you can check out my Github repository.\nHow to use it:\n\nAn Alfred Powerpack is required. (Sorry)\nDownload the workflow from Alfred Gallery.\nDouble click it to install.\nType nba in Alfred.\nPress enter or use the built-in hotkey on a game to see the box score or summary.\n\nExamples\n\n\nCredits\n\nNBA API\nKristjana Ósk for asking me what games were on tonight.\n\n"
      }
    ,
    
    
      
      {
      "title": "Scott Hanson Bot",
      "url": "https://bjornelvar.dev/projects/scott-hanson-bot/",
      "body": "\nDescription\nI created this Discord bot for my Fantasy Football League. I wanted my Discord server to be more interactive and fun, as well as to archive some things, like what was the score in this particular matchup at this particular point in time. I also wanted to be able to see the current standings, current schedule and the top performers for every position and every week.\nI wrote the bot in Python and used the Discord.py library. I also used Beautiful Soup to scrape the data from the league's website. I then used Table2Ascii to output the data in a nice format for the Discord bot to send. The bot was hosted on my friends Raspberry Pi, to update the bot remotely I used a Discord command I wrote that runs a bash script on the Raspberry Pi.\nMy future plans for next season is to refactor the code and make it more modular. Then I would like to use more of the Pandas library to make the code more efficient and easier to read. After that, I would like to implement the yfpy to get historical data from our league.\nExamples\n\n\n\n"
      }
    
    ,
    
      {
      "title": "HIT-SCIR at MRP 2020: Transition-based Parser and Iterative Inference Parser",
      "url": "https://bjornelvar.dev/publications/hit-scir-at-mrp-2020-transition-based-parser-and-iterative-inference-parser/",
      "body": "This paper describes our submission system (HIT-SCIR) for the CoNLL 2020 shared task: Cross-Framework and Cross-Lingual Meaning Representation Parsing. \nThe task includes five frameworks for graph-based meaning representations, i.e., UCCA, EDS, PTG, AMR, and DRG. \nOur solution consists of two sub-systems: \n\ntransition-based parser for Flavor (1) frameworks (UCCA, EDS, PTG)\niterative inference parser for Flavor (2) frameworks (DRG, AMR). \n\nIn the final evaluation, our system is ranked 3rd among the seven team both in Cross-Framework Track and Cross-Lingual Track, with the macro-averaged MRP F1 score of 0.81/0.69.\n"
      }
    ,
    
    
      {
      "title": "N-LTP: A Open-source Neural Chinese Language Technology Platform with Pretrained Models",
      "url": "https://bjornelvar.dev/publications/n-ltp-a-open-source-neural-chinese-language-technology-platform-with-pretrained-models/",
      "body": "An open-source neural language technology platform supporting six fundamental Chinese NLP tasks: \n\nlexical analysis (Chinese word segmentation, part-of-speech tagging, and named entity recognition)\nsyntactic parsing (dependency parsing)\nsemantic parsing (semantic dependency parsing and semantic role labeling). \n\nUnlike the existing state-of-the-art toolkits, such as Stanza, that adopt an independent model for each task, N-LTP adopts the multi-task framework by using a shared pre-trained model, which has the advantage of capturing the shared knowledge across relevant Chinese tasks. \nIn addition, knowledge distillation where the single-task model teaches the multi-task model is further introduced to encourage the multi-task model to surpass its single-task teacher.\nFinally, we provide a collection of easy-to-use APIs and a visualization tool to make users easier to use and view the processing results directly. To the best of our knowledge, this is the first toolkit to support six Chinese NLP fundamental tasks. \n"
      }
    
    ]